<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="王星星"><title>IM系统概览 · 王星星的魔灯</title><meta name="description" content="组里做的IM需要优化，同时这也是我毕设的选题，所以我最近抽空总结了下组里IM的现有流程和架构，其中，就通信流程和同步方式的学习，我获益颇深。
但是，对于缓存失效，性能优化（集群，缓存，异步，批处理），代码抽象等地方还不是很好，还需要我下一步继续改进
一. 通信流程

二. 基础功能用户在上线之后会把"><meta name="keywords" content="王星星的魔灯,博客,王星星"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><!-- 增加网站logo--><link rel="shortcut icon" href="/assets/img/favicon.ico" type="image/x-icon"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><meta name="generator" content="Hexo 5.2.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">王星星的魔灯</a></h3><div class="description"><p>勇士斗恶龙 <br> Love & Seriousness & Regularity & Persistence</p></div></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/wxxlamp"><i class="fa fa-github"></i></a></li><li><a href="mailto:stalern2000@163.com"><i class="fa fa-envelope"></i></a></li><li><a target="_blank" rel="noopener" href="http://wpa.qq.com/msgrd?v=3&amp;uin=2305450070&amp;site=qq&amp;menu=yes"><i class="fa fa-qq"></i></a></li><li><a target="_blank" rel="noopener" href="https://zhihu.com/people/xiao-ming-91-8-39"><i class="fa fa-mortar-board"></i></a></li></ul><div class="footer"><div class="p"><span>© 2018 - 2021</span><i class="fa fa-star"></i><span> 王星星</span><!--span.leancloud_visitors--></div><div class="by_farbox"><span>Powered by</span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo</a><span> &</span><a href="https://github.com/wxxlamp/anatole-core-wxx" target="_blank">Anatole-Wxx</a></div><div class="beian"><a href="http://www.beian.miit.gov.cn/" target="_blank">豫ICP备20004458号-1</a><span style="height:10px;margin-left: 10px;">|</span><img src="/images/gongan.png" style="height:10px;margin-left: 10px;position: relative;top: 1px;"><span style="margin-left: 2px;">豫公网安备 44030400004458号</span></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/categories">分类</a></li><li><a href="/tags">标签</a></li><li><a href="/about">关于</a></li><li><a href="/link">友链</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"></a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>IM系统概览</a></h3></div><div class="post-content"><p>组里做的IM需要优化，同时这也是我毕设的选题，所以我最近抽空总结了下组里IM的现有流程和架构，其中，就通信流程和同步方式的学习，我获益颇深。</p>
<p>但是，对于缓存失效，性能优化（集群，缓存，异步，批处理），代码抽象等地方还不是很好，还需要我下一步继续改进</p>
<h3 id="一-通信流程"><a href="#一-通信流程" class="headerlink" title="一. 通信流程"></a>一. 通信流程</h3><img src="/assets/post/ims-flow.png" align="middle" />

<h3 id="二-基础功能"><a href="#二-基础功能" class="headerlink" title="二. 基础功能"></a>二. 基础功能</h3><p>用户在上线之后会把信息存入redis中，便于后续收发消息。存储的信息包括用户的channel，ack，token，seq，在线人数等</p>
<h4 id="1-单聊-C2C"><a href="#1-单聊-C2C" class="headerlink" title="1. 单聊(C2C)"></a>1. 单聊(C2C)</h4><p>单聊逻辑比较简单，当sender通过长连接把消息发送给server之后，server再把消息(通过RPC/RESTful)转发给route，route将消息和序列号落库之后，再通过redis的缓存，转发给receiver的channel中</p>
<h4 id="2-群聊-C2G"><a href="#2-群聊-C2G" class="headerlink" title="2.  群聊(C2G)"></a>2.  群聊(C2G)</h4><p>我们把群聊和单聊的逻辑基本抽象成一样的，把群也作为一个接受者</p>
<p>群聊的接收方为groupId，第二步业务处理会把receiver的groupId通过查库的方式获得群里面的所有成员，然后再通过Server把消息转发给所有群成员，然后再通过channel发送消息</p>
<h4 id="3-推送-S2C"><a href="#3-推送-S2C" class="headerlink" title="3. 推送(S2C)"></a>3. 推送(S2C)</h4><p>推送并不能通过groupId进行写扩散的优化，所以会存在写入大量msg，并且会大量更新receiver的ack_seq和msg_seq，所以推送需要额外优化</p>
<h3 id="三-消息同步"><a href="#三-消息同步" class="headerlink" title="三. 消息同步"></a>三. 消息同步</h3><h4 id="1-落库方式"><a href="#1-落库方式" class="headerlink" title="1. 落库方式"></a>1. 落库方式</h4><p>msg_seq保存的是消息的seq，以receiverId为粒度自增。last_ack_seq保存的是确认的seq，之所以服务端保存ack是因为如果不保存，当用户换手机之后，就不能获得未读消息了</p>
<ol>
<li>group：msg_seq</li>
<li>group_user: last_ack_seq</li>
<li>message: msg_seq</li>
<li>user: last_ack_seq   msg_seq</li>
</ol>
<p>单聊：消息落库，用户msg_seq<strong>根据userId为粒度自增</strong>，落库更新(1%)，用户ack_seq更新(1%)</p>
<p>群聊：消息落库：群聊msg_seq<strong>根据groupId为粒度自增</strong>，落库更新(1%)，用户群聊ack_seq更新(1%)。**[当群人数很多，同时看到消息的时候，瞬间的ack确认，即是是1%的概率更新数据库也有可能把库打掉]**</p>
<h4 id="2-同步流程"><a href="#2-同步流程" class="headerlink" title="2. 同步流程"></a>2. 同步流程</h4><img src="/assets/post/ims-offline.png" style="zoom: 67%;" />

<h4 id="3-缓存失效"><a href="#3-缓存失效" class="headerlink" title="3. 缓存失效"></a>3. 缓存失效</h4><p>因为msg_seq&amp;ack_seq在Redis中存储，只有1%的概率会同步到DB中，当Redis失效的时候，如何保证用户一定能同步到未读的信息，这也是一个问题。</p>
<blockquote>
<p><strong>以下假设建立在user1离线的情况下</strong></p>
<p>假如在一次C2C中，user1的msg_seq刚好落库，并且此时数据库中的user1_msg_seq是100，同时Redis中的user1_msg_seq也是100。之后user1正常作为receiver接收消息，不过此时并没有触发落库机制</p>
<p>不知道过了多久，数据库中的user1_msg_seq=100(因为没有被1%的几率触发)，Redis的user1_msg_seq是200，说明此时user1已经又接收到了100条数据，但是还没有同步到DB中，此时Redis宕机</p>
</blockquote>
<p>这时，user1的100条数据是丢失的，所以，之前的解决办法是，我们需要重新从数据库中获取旧的seq，同时给其增加10000的步长(对于1%的落库来说，1w几乎能保证一定比宕机的redis的seq大)</p>
<p>对于ack_seq来说，则不存在这种问题，因为我们的ack是从客户端获取的，换句话说，我们服务端的ack是<strong>无状态</strong>的，所以不用考虑1w的步长</p>
<h4 id="4-消息乱序"><a href="#4-消息乱序" class="headerlink" title="4. 消息乱序"></a>4. 消息乱序</h4><p>如果sender发送消息的顺序是1,2，但是receiver接收消息的顺序是2,1，那该如何处理？</p>
<p>我们需要在发送消息时携带上该消息的createTime，然后客户端根据createTime重新调整部分范围内的顺序</p>
<h4 id="5-优化方案"><a href="#5-优化方案" class="headerlink" title="5. 优化方案"></a>5. 优化方案</h4><ol>
<li><strong>同步消息可以需要多次少量同步，不用一次把所有未读消息同步完</strong>，类似于分页查询</li>
<li>可以选择MQ做缓冲，其实对于推送来说，因为不需要及时性，所以可以<strong>通过MQ进行削峰填谷的作用</strong></li>
<li>对于长连接的发送消息来说，额外的落库操作也可以通过另外开辟一个线程落库，或者使用消息队列<strong>异步落库</strong>（同步消息时可能会有延迟），但是消息发送和存储的一致性就没办法保证</li>
<li>落库不能用百分率，因为百分之一对应1w，这个成本是很大的，可以考虑使用固定步长</li>
<li>ack不能每次都落库(1%)，也需要用<strong>步长来落库</strong>[参考微信]</li>
</ol>
<h3 id="四-方案取舍"><a href="#四-方案取舍" class="headerlink" title="四. 方案取舍"></a>四. 方案取舍</h3><h4 id="1-服务器选型"><a href="#1-服务器选型" class="headerlink" title="1. 服务器选型"></a>1. 服务器选型</h4><p>Tomcat还是Netty：暂定基于Netty的原生连接，为了简单易用，选择Yeauty作为WebSocket的脚手架，方便Tomcat到Netty上的迁移。但是如果使用Yeauty，就固定了传输格式，享受不了Netty的自定义网络传输红利</p>
<h4 id="2-通信协议"><a href="#2-通信协议" class="headerlink" title="2. 通信协议"></a>2. 通信协议</h4><ul>
<li>长连接：TCP下的WebSocket还是基于TCP自己解析，暂定基于TCP的ProtoBuf</li>
<li>短连接：目前使用RESTful，后期希望改进为RPC</li>
</ul>
<h4 id="3-读写扩散"><a href="#3-读写扩散" class="headerlink" title="3. 读写扩散"></a>3. 读写扩散</h4><p>读扩散还是<strong>写扩散</strong>，目前是基于写扩散。因为对于我们的业务来说，当群聊人数控制得当，且并发不是很高的情况下，写扩散更容易编写。</p>
<p>同时，把群Id也作为receiver，防止群聊人数过多，增加写扩散的写入压力。同时一次消息也只存入一次msg的实体类，对于ack_seq和msg_seq都是随机更新</p>
<h3 id="五-架构问题"><a href="#五-架构问题" class="headerlink" title="五. 架构问题"></a>五. 架构问题</h3><h4 id="1-服务部署"><a href="#1-服务部署" class="headerlink" title="1. 服务部署"></a>1. 服务部署</h4><p>集群部署，将Netty作为集群部署</p>
<p><strong>在多台服务器中如何路由到receiver的channel中</strong>——需要前置一个route进行路由</p>
<p><strong>每台服务器的注册和服务发现问题</strong>——需要注册中心，可能是Redis，也可能是Zookeeper</p>
<h4 id="2-业务抽象"><a href="#2-业务抽象" class="headerlink" title="2. 业务抽象"></a>2. 业务抽象</h4><p>需要把基本的聊天管道，和建群，好友等模块的业务抽象出来，然后对外提供SDK</p>
<h4 id="3-消息可达"><a href="#3-消息可达" class="headerlink" title="3. 消息可达"></a>3. 消息可达</h4><p>当发送方发送成功或者接送放接收成功消息都会给服务端发送ack，以此来表明自己接收成功</p>
<h3 id="六-监控问题"><a href="#六-监控问题" class="headerlink" title="六. 监控问题"></a>六. 监控问题</h3><p>目前只能监控在线人数，还是有所欠缺的</p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2021-01-15</span><i class="fa fa-tag"></i><a class="tag" href="/tags/IM/" title="IM">IM </a><i class="fa fa-star"></i><a class="tag" href="/categories/架构思考/" title="架构思考">架构思考 </a><span class="leancloud_visitors"></span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="" onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,http://wxxlamp.cn/2021/01/15/im-architecture/,王星星的魔灯,IM系统概览,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2021/01/27/annotation-requestbody/" title="@RequestBody的原理">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2021/01/10/a-little-red-flower-review/" title="《送你一朵小红花》观后感">下一篇</a></li></ul></div><script src="/js/visitors.js"></script><a id="comments"></a><div id="vcomments" style="margin:0 30px;"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/gh/xcss/valine@latest/dist/Valine.min.js"></script><script>var valine = new Valine({
  el:'#vcomments',
  notify:false || false,
  verify:false|| false,
  app_id:'VzGOJC7bFNXeYUEicbM4nOT2-gzGzoHsz',
  app_key:'T3VwGNzVqiWepoUHUQMnh8tP',
  placeholder:'念念不忘，必有回响...',
  path: window.location.pathname,
  serverURLs: '',
  visitor:true,
  recordIP:true,
  avatar:'mp'
})</script></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script src="/js/baidu-tongji.js"></script></body></html>